Venice Biennale: On ALGORITHM
=============================
ESSAY for the DISTRACTION section of the Biennale Thinking Head project by Lara Favaretto  

## Introduction

Thank you all for landing on this article. To begin with, I would like to clarify that I have
refrained from listening to the ALGORITHM Clandestine Talk to avoid being influenced in
any way on my contribution to the DISTRACTION section on this subject. The motivation for
the writing originates from a research I am directly involved with, aimed at bringing to life an
innovative technology that enables everyone to write computational algorithms without the
prerequisite to possess programming skills. I have named this project everknow.it, however
for the DISTRACTION section I intend to be unbiased even from my involvement in this
research and rather produce a contextual scenario that can help us reach some useful
conclusions. Do not hesitate to send me any feedback that you consider relevant if you think
any of what I am about to say could be enriched.

## Context

History suggests, and I did not undergo my due diligence to dig up chronological references,
that we have developed quite early in our evolution a capacity to form models to help us
interact with the complexity of the world we live in. Sensorial inputs are stimulating our
senses in a way that gets subconsciously processed and this leads to a massive process of
synthesis. For instance, in one of our most powerful senses (vision), photons hit our retina
and stimulate chemical reactions that get encoded in electrical signals which then travel
through the synapsys of our optic nerves to reach our brain. Here we can observe a form of
naturally processed algorithm, which is common to other species in the animal kingdom and
is, as it stands today, more powerful and complex than any Artificial Intelligence Machine
Learning Neural Net classifier. The outstanding capacity of our brain, compared to the forms
of automation we have artificially produced so far, is even more marked when this classified
information gets transferred into the conscious activity of our mind. This is where allegedly
free will gets exercised and information gets transformed with intentional, planned purposes.
While we typically consider Neural Net Deep Learning an acceptable simulation of our
classification ability, likely because even its subconscious natural correspondent operates as
a black box, the more conscious part of our mind hasn’t yet been reproduced into a
computational model that is broadly accepted as valid.

## The vision

As we advance into the unknown and uncharted territory that is the modeling of an
algorithmic correspondent to the conscious part of our mind, we have a number of
observations to make.
So far we have proceeded mainly with a rigid logical model which requires that the
production of algorithms follows some schemas defined within the context of a variety of
programming languages. While the approach enables a solid control over the execution (the
primary automation that turns coded rules present in the algorithms into actions), it requires
that the development is operated by particularly trained and skilled individuals. Obviously an
advantage here lays into implementing executions that are making an efficient use of the
scarce and expensive computational resources. The application of a number of optimisation
and heuristic techniques however, while appealing from the point of view of a mind discipline
exercise, end up bringing the humans close to the machine, rather than the machine close to
humans. An algorithm in fact nowadays involves a significant amount of understanding of
how the machine works. This also causes a division in society, as some individuals develop
an instinct, an interest, a predisposition to embrace a rigid and logical approach to problem
solving, an attention to syntactic details and precision, which makes them feel empowered
and somehow more fit to live in the present computational world, while other individuals that
have less interest or inclination to refine these machine-like algorithmic skills, end up
rejecting them and getting effectively excluded. This division turns occasionally bitter,
competitive and even caricatural. I consider this to be one of the major problems we have
spontaneously developed nowadays, and the result is that progress gets somehow stagnant
in both groups.
Hence the effort to bridge this gap and produce computational models that abstract away
from the machine and focus more on what humans want to do and how they do it, rather
than what machines do and how they do it.

## Approaches

I have already touched on the subject of logical symbolic approaches for algorithms, and
addressed them as rigid. This does not necessarily need to be the case. Adaptation in this
area is possible as some of the rules that govern the algorithmic executions can be inferred
from experience or learned from other individuals. As an analogy I would be so bold to state
that what humans typically do among themselves is trade for scripts and rules to better
control other entities present in the world and prepare for events that might occur. These
rules represent the ultimate evolutionary stage of our knowledge and display a number of
patterns that find validity and applicability within an individual perspective or a shared
perspective of a group of individuals. While we can consider this a type of social evolutionary
adaptation, for completeness, we ought to bring up an example of a non-social one, such as
the case of genetic algorithms. These require the definition of a context in which to evolve
and a number of criteria that evaluate the fitness to better respond to the nature of the
environment in which the adaptation takes place. By comparing human driven algorithms
with more spontaneous, automatic and context-driven ones we could observe and measure
how much randomness and entropy play a role in how this evolution takes place. We might
discover that there are other set of rules that we haven’t considered yet and that might fit
better in the very same context we live in. Note as an analogy how Alpha-Go introduced new
moves in the Go game that humans haven’t considered before.

## Conclusions

The goal of this post is merely thought provocative and does not aim to be particularly
enlightening from the scientific perspective, nor it does cover the vast variety of aspects
related to algorithmic executions and evolutions. The main takeaways ought to be that the
currently divided tech and creative communities should learn how to cooperatively explore
new ways to enhance the currently limited algorithmic evolution. Also we ought to be
prepared to compare what we, perhaps arrogantly and yet unchallengedly, consider the
highest form of evolution (our own), against other forms of evolution. I would also take the
opportunity to spread a better awareness that the clock is ticking for us as individuals and as
a collective to conduct our explorations, and we ought to devote our effort towards them
collaboratively rather than competitively. Algorithms in this sense is not something that we
should perceive as obscure and distant, but rather something that enhances and extends
our reach into the unknown.
